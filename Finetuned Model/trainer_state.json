{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.6136433368561006,
  "eval_steps": 1000,
  "global_step": 18000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.003409129649200559,
      "grad_norm": 1.233324646949768,
      "learning_rate": 9.900000000000002e-06,
      "loss": 3.3953,
      "step": 100
    },
    {
      "epoch": 0.006818259298401118,
      "grad_norm": 0.4876210689544678,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 0.5965,
      "step": 200
    },
    {
      "epoch": 0.010227388947601678,
      "grad_norm": 0.549690842628479,
      "learning_rate": 2.9900000000000002e-05,
      "loss": 0.4951,
      "step": 300
    },
    {
      "epoch": 0.013636518596802236,
      "grad_norm": 0.4592573642730713,
      "learning_rate": 3.99e-05,
      "loss": 0.4456,
      "step": 400
    },
    {
      "epoch": 0.017045648246002795,
      "grad_norm": 0.433632493019104,
      "learning_rate": 4.99e-05,
      "loss": 0.4385,
      "step": 500
    },
    {
      "epoch": 0.020454777895203356,
      "grad_norm": 0.7343388795852661,
      "learning_rate": 4.994342792489058e-05,
      "loss": 0.4446,
      "step": 600
    },
    {
      "epoch": 0.023863907544403914,
      "grad_norm": 0.3701871931552887,
      "learning_rate": 4.9886284414679026e-05,
      "loss": 0.4178,
      "step": 700
    },
    {
      "epoch": 0.027273037193604473,
      "grad_norm": 0.49894872307777405,
      "learning_rate": 4.982914090446748e-05,
      "loss": 0.424,
      "step": 800
    },
    {
      "epoch": 0.03068216684280503,
      "grad_norm": 0.35591045022010803,
      "learning_rate": 4.977199739425594e-05,
      "loss": 0.4086,
      "step": 900
    },
    {
      "epoch": 0.03409129649200559,
      "grad_norm": 0.365435391664505,
      "learning_rate": 4.9714853884044396e-05,
      "loss": 0.43,
      "step": 1000
    },
    {
      "epoch": 0.03409129649200559,
      "eval_loss": 0.6416550278663635,
      "eval_runtime": 543.7909,
      "eval_samples_per_second": 23.974,
      "eval_steps_per_second": 5.995,
      "step": 1000
    },
    {
      "epoch": 0.03750042614120615,
      "grad_norm": 12.628281593322754,
      "learning_rate": 4.9657710373832846e-05,
      "loss": 0.4101,
      "step": 1100
    },
    {
      "epoch": 0.04090955579040671,
      "grad_norm": 0.3402453660964966,
      "learning_rate": 4.96005668636213e-05,
      "loss": 0.4107,
      "step": 1200
    },
    {
      "epoch": 0.04431868543960727,
      "grad_norm": 0.6079162955284119,
      "learning_rate": 4.954342335340976e-05,
      "loss": 0.37,
      "step": 1300
    },
    {
      "epoch": 0.04772781508880783,
      "grad_norm": 0.32242414355278015,
      "learning_rate": 4.948627984319821e-05,
      "loss": 0.3758,
      "step": 1400
    },
    {
      "epoch": 0.05113694473800839,
      "grad_norm": 0.5206154584884644,
      "learning_rate": 4.9429136332986666e-05,
      "loss": 0.3948,
      "step": 1500
    },
    {
      "epoch": 0.054546074387208945,
      "grad_norm": 0.42796698212623596,
      "learning_rate": 4.937199282277512e-05,
      "loss": 0.3724,
      "step": 1600
    },
    {
      "epoch": 0.057955204036409504,
      "grad_norm": 0.35282102227211,
      "learning_rate": 4.931484931256358e-05,
      "loss": 0.3578,
      "step": 1700
    },
    {
      "epoch": 0.06136433368561006,
      "grad_norm": 0.4132536053657532,
      "learning_rate": 4.925770580235203e-05,
      "loss": 0.365,
      "step": 1800
    },
    {
      "epoch": 0.06477346333481063,
      "grad_norm": 0.6116577386856079,
      "learning_rate": 4.9200562292140485e-05,
      "loss": 0.3815,
      "step": 1900
    },
    {
      "epoch": 0.06818259298401118,
      "grad_norm": 0.36712580919265747,
      "learning_rate": 4.914341878192894e-05,
      "loss": 0.3817,
      "step": 2000
    },
    {
      "epoch": 0.06818259298401118,
      "eval_loss": 0.617315411567688,
      "eval_runtime": 544.2389,
      "eval_samples_per_second": 23.955,
      "eval_steps_per_second": 5.99,
      "step": 2000
    },
    {
      "epoch": 0.07159172263321174,
      "grad_norm": 0.39369627833366394,
      "learning_rate": 4.908627527171739e-05,
      "loss": 0.3925,
      "step": 2100
    },
    {
      "epoch": 0.0750008522824123,
      "grad_norm": 0.6381937861442566,
      "learning_rate": 4.902913176150585e-05,
      "loss": 0.3708,
      "step": 2200
    },
    {
      "epoch": 0.07840998193161286,
      "grad_norm": 0.40647250413894653,
      "learning_rate": 4.8971988251294305e-05,
      "loss": 0.3548,
      "step": 2300
    },
    {
      "epoch": 0.08181911158081343,
      "grad_norm": 0.505611002445221,
      "learning_rate": 4.8914844741082754e-05,
      "loss": 0.3685,
      "step": 2400
    },
    {
      "epoch": 0.08522824123001398,
      "grad_norm": 0.3859076499938965,
      "learning_rate": 4.885770123087121e-05,
      "loss": 0.3624,
      "step": 2500
    },
    {
      "epoch": 0.08863737087921454,
      "grad_norm": 0.2440304309129715,
      "learning_rate": 4.880055772065967e-05,
      "loss": 0.3761,
      "step": 2600
    },
    {
      "epoch": 0.09204650052841509,
      "grad_norm": 0.35656070709228516,
      "learning_rate": 4.8743414210448124e-05,
      "loss": 0.3733,
      "step": 2700
    },
    {
      "epoch": 0.09545563017761566,
      "grad_norm": 0.29475322365760803,
      "learning_rate": 4.8686270700236574e-05,
      "loss": 0.37,
      "step": 2800
    },
    {
      "epoch": 0.09886475982681621,
      "grad_norm": 0.5124595761299133,
      "learning_rate": 4.862912719002503e-05,
      "loss": 0.3842,
      "step": 2900
    },
    {
      "epoch": 0.10227388947601677,
      "grad_norm": 0.43753713369369507,
      "learning_rate": 4.857198367981349e-05,
      "loss": 0.3841,
      "step": 3000
    },
    {
      "epoch": 0.10227388947601677,
      "eval_loss": 0.6121833324432373,
      "eval_runtime": 545.7182,
      "eval_samples_per_second": 23.89,
      "eval_steps_per_second": 5.974,
      "step": 3000
    },
    {
      "epoch": 0.10568301912521733,
      "grad_norm": 0.3009374141693115,
      "learning_rate": 4.851484016960194e-05,
      "loss": 0.3847,
      "step": 3100
    },
    {
      "epoch": 0.10909214877441789,
      "grad_norm": 0.38301312923431396,
      "learning_rate": 4.845769665939039e-05,
      "loss": 0.3599,
      "step": 3200
    },
    {
      "epoch": 0.11250127842361846,
      "grad_norm": 0.7394877076148987,
      "learning_rate": 4.840055314917885e-05,
      "loss": 0.3604,
      "step": 3300
    },
    {
      "epoch": 0.11591040807281901,
      "grad_norm": 0.5243735313415527,
      "learning_rate": 4.8343409638967306e-05,
      "loss": 0.3611,
      "step": 3400
    },
    {
      "epoch": 0.11931953772201957,
      "grad_norm": 0.5473337769508362,
      "learning_rate": 4.8286266128755756e-05,
      "loss": 0.3745,
      "step": 3500
    },
    {
      "epoch": 0.12272866737122012,
      "grad_norm": 0.33710911870002747,
      "learning_rate": 4.822912261854421e-05,
      "loss": 0.3578,
      "step": 3600
    },
    {
      "epoch": 0.1261377970204207,
      "grad_norm": 0.4120584726333618,
      "learning_rate": 4.817197910833267e-05,
      "loss": 0.3536,
      "step": 3700
    },
    {
      "epoch": 0.12954692666962125,
      "grad_norm": 0.4336208403110504,
      "learning_rate": 4.811483559812112e-05,
      "loss": 0.3656,
      "step": 3800
    },
    {
      "epoch": 0.1329560563188218,
      "grad_norm": 0.6457061767578125,
      "learning_rate": 4.8057692087909576e-05,
      "loss": 0.3715,
      "step": 3900
    },
    {
      "epoch": 0.13636518596802236,
      "grad_norm": 0.3092363774776459,
      "learning_rate": 4.800054857769803e-05,
      "loss": 0.3664,
      "step": 4000
    },
    {
      "epoch": 0.13636518596802236,
      "eval_loss": 0.6068258881568909,
      "eval_runtime": 543.4946,
      "eval_samples_per_second": 23.987,
      "eval_steps_per_second": 5.998,
      "step": 4000
    },
    {
      "epoch": 0.13977431561722292,
      "grad_norm": 0.4056329131126404,
      "learning_rate": 4.794340506748648e-05,
      "loss": 0.3457,
      "step": 4100
    },
    {
      "epoch": 0.1431834452664235,
      "grad_norm": 0.446309357881546,
      "learning_rate": 4.788626155727494e-05,
      "loss": 0.3801,
      "step": 4200
    },
    {
      "epoch": 0.14659257491562405,
      "grad_norm": 0.3500822186470032,
      "learning_rate": 4.7829118047063395e-05,
      "loss": 0.3744,
      "step": 4300
    },
    {
      "epoch": 0.1500017045648246,
      "grad_norm": 0.3795892596244812,
      "learning_rate": 4.777197453685185e-05,
      "loss": 0.3855,
      "step": 4400
    },
    {
      "epoch": 0.15341083421402515,
      "grad_norm": 0.557341992855072,
      "learning_rate": 4.771483102664031e-05,
      "loss": 0.3576,
      "step": 4500
    },
    {
      "epoch": 0.15681996386322572,
      "grad_norm": 0.38837334513664246,
      "learning_rate": 4.7657687516428765e-05,
      "loss": 0.3477,
      "step": 4600
    },
    {
      "epoch": 0.16022909351242628,
      "grad_norm": 0.3845652639865875,
      "learning_rate": 4.7600544006217215e-05,
      "loss": 0.379,
      "step": 4700
    },
    {
      "epoch": 0.16363822316162685,
      "grad_norm": 0.4781402051448822,
      "learning_rate": 4.754340049600567e-05,
      "loss": 0.3491,
      "step": 4800
    },
    {
      "epoch": 0.1670473528108274,
      "grad_norm": 0.3545587658882141,
      "learning_rate": 4.748625698579413e-05,
      "loss": 0.3792,
      "step": 4900
    },
    {
      "epoch": 0.17045648246002795,
      "grad_norm": 0.4334039092063904,
      "learning_rate": 4.7429113475582585e-05,
      "loss": 0.371,
      "step": 5000
    },
    {
      "epoch": 0.17045648246002795,
      "eval_loss": 0.6030338406562805,
      "eval_runtime": 542.668,
      "eval_samples_per_second": 24.024,
      "eval_steps_per_second": 6.007,
      "step": 5000
    },
    {
      "epoch": 0.17386561210922852,
      "grad_norm": 0.3730129599571228,
      "learning_rate": 4.7371969965371034e-05,
      "loss": 0.367,
      "step": 5100
    },
    {
      "epoch": 0.17727474175842908,
      "grad_norm": 0.24282675981521606,
      "learning_rate": 4.731482645515949e-05,
      "loss": 0.3559,
      "step": 5200
    },
    {
      "epoch": 0.18068387140762962,
      "grad_norm": 0.4380103647708893,
      "learning_rate": 4.725768294494795e-05,
      "loss": 0.3647,
      "step": 5300
    },
    {
      "epoch": 0.18409300105683019,
      "grad_norm": 0.3685339391231537,
      "learning_rate": 4.7200539434736404e-05,
      "loss": 0.3747,
      "step": 5400
    },
    {
      "epoch": 0.18750213070603075,
      "grad_norm": 0.2673991322517395,
      "learning_rate": 4.7143395924524854e-05,
      "loss": 0.3377,
      "step": 5500
    },
    {
      "epoch": 0.19091126035523132,
      "grad_norm": 0.35524243116378784,
      "learning_rate": 4.708625241431331e-05,
      "loss": 0.3609,
      "step": 5600
    },
    {
      "epoch": 0.19432039000443188,
      "grad_norm": 0.42562827467918396,
      "learning_rate": 4.702910890410177e-05,
      "loss": 0.3671,
      "step": 5700
    },
    {
      "epoch": 0.19772951965363242,
      "grad_norm": 0.4726366698741913,
      "learning_rate": 4.697196539389022e-05,
      "loss": 0.3722,
      "step": 5800
    },
    {
      "epoch": 0.20113864930283298,
      "grad_norm": 0.48624730110168457,
      "learning_rate": 4.691482188367867e-05,
      "loss": 0.3385,
      "step": 5900
    },
    {
      "epoch": 0.20454777895203355,
      "grad_norm": 0.3615987300872803,
      "learning_rate": 4.685767837346713e-05,
      "loss": 0.3869,
      "step": 6000
    },
    {
      "epoch": 0.20454777895203355,
      "eval_loss": 0.5995154976844788,
      "eval_runtime": 545.0594,
      "eval_samples_per_second": 23.918,
      "eval_steps_per_second": 5.981,
      "step": 6000
    },
    {
      "epoch": 0.20795690860123411,
      "grad_norm": 0.39820194244384766,
      "learning_rate": 4.680053486325558e-05,
      "loss": 0.3473,
      "step": 6100
    },
    {
      "epoch": 0.21136603825043465,
      "grad_norm": 0.33196285367012024,
      "learning_rate": 4.6743391353044036e-05,
      "loss": 0.3476,
      "step": 6200
    },
    {
      "epoch": 0.21477516789963522,
      "grad_norm": 0.423473984003067,
      "learning_rate": 4.668624784283249e-05,
      "loss": 0.3816,
      "step": 6300
    },
    {
      "epoch": 0.21818429754883578,
      "grad_norm": 0.37430238723754883,
      "learning_rate": 4.662910433262095e-05,
      "loss": 0.3806,
      "step": 6400
    },
    {
      "epoch": 0.22159342719803635,
      "grad_norm": 0.34450602531433105,
      "learning_rate": 4.65719608224094e-05,
      "loss": 0.3728,
      "step": 6500
    },
    {
      "epoch": 0.2250025568472369,
      "grad_norm": 0.45655933022499084,
      "learning_rate": 4.6514817312197856e-05,
      "loss": 0.3597,
      "step": 6600
    },
    {
      "epoch": 0.22841168649643745,
      "grad_norm": 0.3529870808124542,
      "learning_rate": 4.645767380198631e-05,
      "loss": 0.3558,
      "step": 6700
    },
    {
      "epoch": 0.23182081614563801,
      "grad_norm": 0.511701762676239,
      "learning_rate": 4.640053029177476e-05,
      "loss": 0.3634,
      "step": 6800
    },
    {
      "epoch": 0.23522994579483858,
      "grad_norm": 0.3075192868709564,
      "learning_rate": 4.634338678156322e-05,
      "loss": 0.36,
      "step": 6900
    },
    {
      "epoch": 0.23863907544403914,
      "grad_norm": 0.47382646799087524,
      "learning_rate": 4.6286243271351675e-05,
      "loss": 0.3735,
      "step": 7000
    },
    {
      "epoch": 0.23863907544403914,
      "eval_loss": 0.5948424935340881,
      "eval_runtime": 544.0275,
      "eval_samples_per_second": 23.964,
      "eval_steps_per_second": 5.992,
      "step": 7000
    },
    {
      "epoch": 0.24204820509323968,
      "grad_norm": 0.33246955275535583,
      "learning_rate": 4.622909976114013e-05,
      "loss": 0.368,
      "step": 7100
    },
    {
      "epoch": 0.24545733474244025,
      "grad_norm": 0.37226077914237976,
      "learning_rate": 4.617195625092858e-05,
      "loss": 0.3474,
      "step": 7200
    },
    {
      "epoch": 0.2488664643916408,
      "grad_norm": 0.2925775647163391,
      "learning_rate": 4.611481274071704e-05,
      "loss": 0.351,
      "step": 7300
    },
    {
      "epoch": 0.2522755940408414,
      "grad_norm": 0.4381227195262909,
      "learning_rate": 4.6057669230505495e-05,
      "loss": 0.353,
      "step": 7400
    },
    {
      "epoch": 0.2556847236900419,
      "grad_norm": 0.3018834888935089,
      "learning_rate": 4.6000525720293945e-05,
      "loss": 0.3584,
      "step": 7500
    },
    {
      "epoch": 0.2590938533392425,
      "grad_norm": 0.38155797123908997,
      "learning_rate": 4.59433822100824e-05,
      "loss": 0.3595,
      "step": 7600
    },
    {
      "epoch": 0.26250298298844305,
      "grad_norm": 0.9000658392906189,
      "learning_rate": 4.588623869987086e-05,
      "loss": 0.3523,
      "step": 7700
    },
    {
      "epoch": 0.2659121126376436,
      "grad_norm": 0.4025292694568634,
      "learning_rate": 4.582909518965931e-05,
      "loss": 0.3638,
      "step": 7800
    },
    {
      "epoch": 0.2693212422868442,
      "grad_norm": 0.3991919755935669,
      "learning_rate": 4.5771951679447764e-05,
      "loss": 0.3524,
      "step": 7900
    },
    {
      "epoch": 0.2727303719360447,
      "grad_norm": 0.4211803078651428,
      "learning_rate": 4.571480816923622e-05,
      "loss": 0.3577,
      "step": 8000
    },
    {
      "epoch": 0.2727303719360447,
      "eval_loss": 0.5944870114326477,
      "eval_runtime": 543.9996,
      "eval_samples_per_second": 23.965,
      "eval_steps_per_second": 5.993,
      "step": 8000
    },
    {
      "epoch": 0.2761395015852453,
      "grad_norm": 0.39328622817993164,
      "learning_rate": 4.565766465902468e-05,
      "loss": 0.3599,
      "step": 8100
    },
    {
      "epoch": 0.27954863123444584,
      "grad_norm": 0.2753141522407532,
      "learning_rate": 4.560052114881313e-05,
      "loss": 0.3798,
      "step": 8200
    },
    {
      "epoch": 0.2829577608836464,
      "grad_norm": 0.3648013174533844,
      "learning_rate": 4.5543377638601584e-05,
      "loss": 0.3731,
      "step": 8300
    },
    {
      "epoch": 0.286366890532847,
      "grad_norm": 0.4645503759384155,
      "learning_rate": 4.548623412839004e-05,
      "loss": 0.359,
      "step": 8400
    },
    {
      "epoch": 0.2897760201820475,
      "grad_norm": 0.35651805996894836,
      "learning_rate": 4.54290906181785e-05,
      "loss": 0.3504,
      "step": 8500
    },
    {
      "epoch": 0.2931851498312481,
      "grad_norm": 0.4955185055732727,
      "learning_rate": 4.537194710796695e-05,
      "loss": 0.3564,
      "step": 8600
    },
    {
      "epoch": 0.29659427948044864,
      "grad_norm": 0.2979781925678253,
      "learning_rate": 4.53148035977554e-05,
      "loss": 0.3632,
      "step": 8700
    },
    {
      "epoch": 0.3000034091296492,
      "grad_norm": 0.3723369538784027,
      "learning_rate": 4.525766008754386e-05,
      "loss": 0.3694,
      "step": 8800
    },
    {
      "epoch": 0.30341253877884977,
      "grad_norm": 0.43102964758872986,
      "learning_rate": 4.5200516577332316e-05,
      "loss": 0.3616,
      "step": 8900
    },
    {
      "epoch": 0.3068216684280503,
      "grad_norm": 0.4508126974105835,
      "learning_rate": 4.514337306712077e-05,
      "loss": 0.3681,
      "step": 9000
    },
    {
      "epoch": 0.3068216684280503,
      "eval_loss": 0.5923543572425842,
      "eval_runtime": 543.6901,
      "eval_samples_per_second": 23.979,
      "eval_steps_per_second": 5.996,
      "step": 9000
    },
    {
      "epoch": 0.3102307980772509,
      "grad_norm": 0.43908706307411194,
      "learning_rate": 4.508622955690923e-05,
      "loss": 0.3641,
      "step": 9100
    },
    {
      "epoch": 0.31363992772645144,
      "grad_norm": 0.34080010652542114,
      "learning_rate": 4.502908604669768e-05,
      "loss": 0.3483,
      "step": 9200
    },
    {
      "epoch": 0.317049057375652,
      "grad_norm": 0.4099982678890228,
      "learning_rate": 4.4971942536486136e-05,
      "loss": 0.328,
      "step": 9300
    },
    {
      "epoch": 0.32045818702485257,
      "grad_norm": 0.28002241253852844,
      "learning_rate": 4.491479902627459e-05,
      "loss": 0.3553,
      "step": 9400
    },
    {
      "epoch": 0.3238673166740531,
      "grad_norm": 0.4874763488769531,
      "learning_rate": 4.485765551606304e-05,
      "loss": 0.3794,
      "step": 9500
    },
    {
      "epoch": 0.3272764463232537,
      "grad_norm": 0.5981332063674927,
      "learning_rate": 4.48005120058515e-05,
      "loss": 0.3792,
      "step": 9600
    },
    {
      "epoch": 0.33068557597245424,
      "grad_norm": 0.3793618679046631,
      "learning_rate": 4.4743368495639955e-05,
      "loss": 0.3315,
      "step": 9700
    },
    {
      "epoch": 0.3340947056216548,
      "grad_norm": 0.3306550681591034,
      "learning_rate": 4.4686224985428405e-05,
      "loss": 0.3746,
      "step": 9800
    },
    {
      "epoch": 0.33750383527085537,
      "grad_norm": 0.3375961184501648,
      "learning_rate": 4.462908147521686e-05,
      "loss": 0.3592,
      "step": 9900
    },
    {
      "epoch": 0.3409129649200559,
      "grad_norm": 0.3786032497882843,
      "learning_rate": 4.457193796500532e-05,
      "loss": 0.3592,
      "step": 10000
    },
    {
      "epoch": 0.3409129649200559,
      "eval_loss": 0.5879574418067932,
      "eval_runtime": 544.7909,
      "eval_samples_per_second": 23.93,
      "eval_steps_per_second": 5.984,
      "step": 10000
    },
    {
      "epoch": 0.34432209456925644,
      "grad_norm": 0.4020206034183502,
      "learning_rate": 4.4514794454793775e-05,
      "loss": 0.372,
      "step": 10100
    },
    {
      "epoch": 0.34773122421845704,
      "grad_norm": 0.3074813187122345,
      "learning_rate": 4.4457650944582225e-05,
      "loss": 0.3623,
      "step": 10200
    },
    {
      "epoch": 0.3511403538676576,
      "grad_norm": 0.32620182633399963,
      "learning_rate": 4.440050743437068e-05,
      "loss": 0.3597,
      "step": 10300
    },
    {
      "epoch": 0.35454948351685817,
      "grad_norm": 0.32313042879104614,
      "learning_rate": 4.434336392415914e-05,
      "loss": 0.3503,
      "step": 10400
    },
    {
      "epoch": 0.3579586131660587,
      "grad_norm": 0.4109112322330475,
      "learning_rate": 4.428622041394759e-05,
      "loss": 0.3479,
      "step": 10500
    },
    {
      "epoch": 0.36136774281525924,
      "grad_norm": 0.385979026556015,
      "learning_rate": 4.4229076903736044e-05,
      "loss": 0.3472,
      "step": 10600
    },
    {
      "epoch": 0.36477687246445983,
      "grad_norm": 0.2589503526687622,
      "learning_rate": 4.41719333935245e-05,
      "loss": 0.3654,
      "step": 10700
    },
    {
      "epoch": 0.36818600211366037,
      "grad_norm": 0.2626204192638397,
      "learning_rate": 4.411478988331296e-05,
      "loss": 0.346,
      "step": 10800
    },
    {
      "epoch": 0.37159513176286096,
      "grad_norm": 0.5563777685165405,
      "learning_rate": 4.405764637310141e-05,
      "loss": 0.3654,
      "step": 10900
    },
    {
      "epoch": 0.3750042614120615,
      "grad_norm": 0.3766571879386902,
      "learning_rate": 4.4000502862889864e-05,
      "loss": 0.3424,
      "step": 11000
    },
    {
      "epoch": 0.3750042614120615,
      "eval_loss": 0.5897399187088013,
      "eval_runtime": 543.9751,
      "eval_samples_per_second": 23.966,
      "eval_steps_per_second": 5.993,
      "step": 11000
    },
    {
      "epoch": 0.37841339106126204,
      "grad_norm": 0.45467400550842285,
      "learning_rate": 4.394335935267832e-05,
      "loss": 0.3681,
      "step": 11100
    },
    {
      "epoch": 0.38182252071046263,
      "grad_norm": 0.32022035121917725,
      "learning_rate": 4.388621584246677e-05,
      "loss": 0.3591,
      "step": 11200
    },
    {
      "epoch": 0.38523165035966317,
      "grad_norm": 0.37196609377861023,
      "learning_rate": 4.3829072332255226e-05,
      "loss": 0.3692,
      "step": 11300
    },
    {
      "epoch": 0.38864078000886376,
      "grad_norm": 0.31829333305358887,
      "learning_rate": 4.377192882204368e-05,
      "loss": 0.3572,
      "step": 11400
    },
    {
      "epoch": 0.3920499096580643,
      "grad_norm": 0.41103896498680115,
      "learning_rate": 4.371478531183213e-05,
      "loss": 0.3517,
      "step": 11500
    },
    {
      "epoch": 0.39545903930726484,
      "grad_norm": 0.2571130692958832,
      "learning_rate": 4.365764180162059e-05,
      "loss": 0.3558,
      "step": 11600
    },
    {
      "epoch": 0.39886816895646543,
      "grad_norm": 0.4974956214427948,
      "learning_rate": 4.3600498291409046e-05,
      "loss": 0.3318,
      "step": 11700
    },
    {
      "epoch": 0.40227729860566597,
      "grad_norm": 0.4214082658290863,
      "learning_rate": 4.35433547811975e-05,
      "loss": 0.3442,
      "step": 11800
    },
    {
      "epoch": 0.40568642825486656,
      "grad_norm": 0.4070371687412262,
      "learning_rate": 4.348621127098595e-05,
      "loss": 0.3611,
      "step": 11900
    },
    {
      "epoch": 0.4090955579040671,
      "grad_norm": 0.4138445258140564,
      "learning_rate": 4.342906776077441e-05,
      "loss": 0.3764,
      "step": 12000
    },
    {
      "epoch": 0.4090955579040671,
      "eval_loss": 0.5875555872917175,
      "eval_runtime": 544.4381,
      "eval_samples_per_second": 23.946,
      "eval_steps_per_second": 5.988,
      "step": 12000
    },
    {
      "epoch": 0.41250468755326763,
      "grad_norm": 0.42745885252952576,
      "learning_rate": 4.3371924250562865e-05,
      "loss": 0.3613,
      "step": 12100
    },
    {
      "epoch": 0.41591381720246823,
      "grad_norm": 0.5324268341064453,
      "learning_rate": 4.3314780740351315e-05,
      "loss": 0.3612,
      "step": 12200
    },
    {
      "epoch": 0.41932294685166877,
      "grad_norm": 0.6042847633361816,
      "learning_rate": 4.325763723013977e-05,
      "loss": 0.3716,
      "step": 12300
    },
    {
      "epoch": 0.4227320765008693,
      "grad_norm": 0.5159546732902527,
      "learning_rate": 4.320049371992823e-05,
      "loss": 0.3511,
      "step": 12400
    },
    {
      "epoch": 0.4261412061500699,
      "grad_norm": 0.4539298713207245,
      "learning_rate": 4.3143350209716685e-05,
      "loss": 0.3488,
      "step": 12500
    },
    {
      "epoch": 0.42955033579927043,
      "grad_norm": 0.41048088669776917,
      "learning_rate": 4.308620669950514e-05,
      "loss": 0.348,
      "step": 12600
    },
    {
      "epoch": 0.432959465448471,
      "grad_norm": 0.31778576970100403,
      "learning_rate": 4.302906318929359e-05,
      "loss": 0.3695,
      "step": 12700
    },
    {
      "epoch": 0.43636859509767156,
      "grad_norm": 0.41028597950935364,
      "learning_rate": 4.297191967908205e-05,
      "loss": 0.3806,
      "step": 12800
    },
    {
      "epoch": 0.4397777247468721,
      "grad_norm": 0.38379940390586853,
      "learning_rate": 4.2914776168870505e-05,
      "loss": 0.3729,
      "step": 12900
    },
    {
      "epoch": 0.4431868543960727,
      "grad_norm": 0.3482206165790558,
      "learning_rate": 4.285763265865896e-05,
      "loss": 0.3423,
      "step": 13000
    },
    {
      "epoch": 0.4431868543960727,
      "eval_loss": 0.5855070948600769,
      "eval_runtime": 543.4972,
      "eval_samples_per_second": 23.987,
      "eval_steps_per_second": 5.998,
      "step": 13000
    },
    {
      "epoch": 0.44659598404527323,
      "grad_norm": 0.39106330275535583,
      "learning_rate": 4.280048914844742e-05,
      "loss": 0.3769,
      "step": 13100
    },
    {
      "epoch": 0.4500051136944738,
      "grad_norm": 0.2610946595668793,
      "learning_rate": 4.274334563823587e-05,
      "loss": 0.3551,
      "step": 13200
    },
    {
      "epoch": 0.45341424334367436,
      "grad_norm": 0.4573317766189575,
      "learning_rate": 4.2686202128024324e-05,
      "loss": 0.359,
      "step": 13300
    },
    {
      "epoch": 0.4568233729928749,
      "grad_norm": 0.48661288619041443,
      "learning_rate": 4.262905861781278e-05,
      "loss": 0.3674,
      "step": 13400
    },
    {
      "epoch": 0.4602325026420755,
      "grad_norm": 0.28946641087532043,
      "learning_rate": 4.257191510760123e-05,
      "loss": 0.343,
      "step": 13500
    },
    {
      "epoch": 0.46364163229127603,
      "grad_norm": 0.4488266408443451,
      "learning_rate": 4.251477159738969e-05,
      "loss": 0.3514,
      "step": 13600
    },
    {
      "epoch": 0.4670507619404766,
      "grad_norm": 0.31920063495635986,
      "learning_rate": 4.2457628087178144e-05,
      "loss": 0.359,
      "step": 13700
    },
    {
      "epoch": 0.47045989158967716,
      "grad_norm": 0.46442902088165283,
      "learning_rate": 4.24004845769666e-05,
      "loss": 0.3467,
      "step": 13800
    },
    {
      "epoch": 0.4738690212388777,
      "grad_norm": 0.43230780959129333,
      "learning_rate": 4.234334106675505e-05,
      "loss": 0.3415,
      "step": 13900
    },
    {
      "epoch": 0.4772781508880783,
      "grad_norm": 0.4648909270763397,
      "learning_rate": 4.2286197556543506e-05,
      "loss": 0.3542,
      "step": 14000
    },
    {
      "epoch": 0.4772781508880783,
      "eval_loss": 0.5846272110939026,
      "eval_runtime": 545.0026,
      "eval_samples_per_second": 23.921,
      "eval_steps_per_second": 5.982,
      "step": 14000
    },
    {
      "epoch": 0.4806872805372788,
      "grad_norm": 0.3545888364315033,
      "learning_rate": 4.222905404633196e-05,
      "loss": 0.3568,
      "step": 14100
    },
    {
      "epoch": 0.48409641018647936,
      "grad_norm": 0.32665789127349854,
      "learning_rate": 4.217191053612041e-05,
      "loss": 0.3351,
      "step": 14200
    },
    {
      "epoch": 0.48750553983567996,
      "grad_norm": 0.24791845679283142,
      "learning_rate": 4.211476702590887e-05,
      "loss": 0.3726,
      "step": 14300
    },
    {
      "epoch": 0.4909146694848805,
      "grad_norm": 0.4529562294483185,
      "learning_rate": 4.2057623515697326e-05,
      "loss": 0.3697,
      "step": 14400
    },
    {
      "epoch": 0.4943237991340811,
      "grad_norm": 0.4205506443977356,
      "learning_rate": 4.200048000548578e-05,
      "loss": 0.3539,
      "step": 14500
    },
    {
      "epoch": 0.4977329287832816,
      "grad_norm": 0.2985076904296875,
      "learning_rate": 4.194333649527423e-05,
      "loss": 0.347,
      "step": 14600
    },
    {
      "epoch": 0.5011420584324822,
      "grad_norm": 0.43062520027160645,
      "learning_rate": 4.188619298506269e-05,
      "loss": 0.3715,
      "step": 14700
    },
    {
      "epoch": 0.5045511880816828,
      "grad_norm": 0.2816789746284485,
      "learning_rate": 4.1829049474851145e-05,
      "loss": 0.3342,
      "step": 14800
    },
    {
      "epoch": 0.5079603177308833,
      "grad_norm": 0.3574533462524414,
      "learning_rate": 4.1771905964639595e-05,
      "loss": 0.373,
      "step": 14900
    },
    {
      "epoch": 0.5113694473800838,
      "grad_norm": 0.2860797643661499,
      "learning_rate": 4.171476245442805e-05,
      "loss": 0.3664,
      "step": 15000
    },
    {
      "epoch": 0.5113694473800838,
      "eval_loss": 0.5836674571037292,
      "eval_runtime": 543.862,
      "eval_samples_per_second": 23.971,
      "eval_steps_per_second": 5.994,
      "step": 15000
    },
    {
      "epoch": 0.5147785770292844,
      "grad_norm": 0.10264623910188675,
      "learning_rate": 4.165761894421651e-05,
      "loss": 0.1798,
      "step": 15100
    },
    {
      "epoch": 0.518187706678485,
      "grad_norm": 0.11147652566432953,
      "learning_rate": 4.160047543400496e-05,
      "loss": 0.1211,
      "step": 15200
    },
    {
      "epoch": 0.5215968363276855,
      "grad_norm": 0.09474220871925354,
      "learning_rate": 4.1543331923793415e-05,
      "loss": 0.1263,
      "step": 15300
    },
    {
      "epoch": 0.5250059659768861,
      "grad_norm": 0.1417139768600464,
      "learning_rate": 4.148618841358187e-05,
      "loss": 0.1224,
      "step": 15400
    },
    {
      "epoch": 0.5284150956260867,
      "grad_norm": 0.13748790323734283,
      "learning_rate": 4.142904490337033e-05,
      "loss": 0.1242,
      "step": 15500
    },
    {
      "epoch": 0.5318242252752872,
      "grad_norm": 0.08304951339960098,
      "learning_rate": 4.137190139315878e-05,
      "loss": 0.1221,
      "step": 15600
    },
    {
      "epoch": 0.5352333549244878,
      "grad_norm": 0.08104970306158066,
      "learning_rate": 4.1314757882947234e-05,
      "loss": 0.1168,
      "step": 15700
    },
    {
      "epoch": 0.5386424845736884,
      "grad_norm": 0.1476733386516571,
      "learning_rate": 4.125761437273569e-05,
      "loss": 0.1307,
      "step": 15800
    },
    {
      "epoch": 0.5420516142228889,
      "grad_norm": 0.2357971966266632,
      "learning_rate": 4.120047086252414e-05,
      "loss": 0.1212,
      "step": 15900
    },
    {
      "epoch": 0.5454607438720894,
      "grad_norm": 0.09954915195703506,
      "learning_rate": 4.11433273523126e-05,
      "loss": 0.1179,
      "step": 16000
    },
    {
      "epoch": 0.5454607438720894,
      "eval_loss": 0.11538978666067123,
      "eval_runtime": 1600.6837,
      "eval_samples_per_second": 8.145,
      "eval_steps_per_second": 2.037,
      "step": 16000
    },
    {
      "epoch": 0.54886987352129,
      "grad_norm": 0.22610752284526825,
      "learning_rate": 4.1086183842101054e-05,
      "loss": 0.1217,
      "step": 16100
    },
    {
      "epoch": 0.5522790031704906,
      "grad_norm": 0.11694427579641342,
      "learning_rate": 4.1029040331889504e-05,
      "loss": 0.1207,
      "step": 16200
    },
    {
      "epoch": 0.5556881328196911,
      "grad_norm": 0.1397562026977539,
      "learning_rate": 4.097189682167796e-05,
      "loss": 0.1145,
      "step": 16300
    },
    {
      "epoch": 0.5590972624688917,
      "grad_norm": 0.1214393898844719,
      "learning_rate": 4.091475331146642e-05,
      "loss": 0.1192,
      "step": 16400
    },
    {
      "epoch": 0.5625063921180923,
      "grad_norm": 0.15944358706474304,
      "learning_rate": 4.085760980125487e-05,
      "loss": 0.1182,
      "step": 16500
    },
    {
      "epoch": 0.5659155217672928,
      "grad_norm": 0.1002017930150032,
      "learning_rate": 4.080046629104333e-05,
      "loss": 0.1154,
      "step": 16600
    },
    {
      "epoch": 0.5693246514164934,
      "grad_norm": 0.13346314430236816,
      "learning_rate": 4.074332278083178e-05,
      "loss": 0.1154,
      "step": 16700
    },
    {
      "epoch": 0.572733781065694,
      "grad_norm": 0.1480603814125061,
      "learning_rate": 4.0686179270620236e-05,
      "loss": 0.1219,
      "step": 16800
    },
    {
      "epoch": 0.5761429107148945,
      "grad_norm": 0.1605762243270874,
      "learning_rate": 4.062903576040869e-05,
      "loss": 0.1162,
      "step": 16900
    },
    {
      "epoch": 0.579552040364095,
      "grad_norm": 0.13529908657073975,
      "learning_rate": 4.057189225019715e-05,
      "loss": 0.1171,
      "step": 17000
    },
    {
      "epoch": 0.579552040364095,
      "eval_loss": 0.11511678248643875,
      "eval_runtime": 1599.962,
      "eval_samples_per_second": 8.148,
      "eval_steps_per_second": 2.038,
      "step": 17000
    },
    {
      "epoch": 0.5829611700132956,
      "grad_norm": 0.1461089849472046,
      "learning_rate": 4.0514748739985606e-05,
      "loss": 0.1175,
      "step": 17100
    },
    {
      "epoch": 0.5863702996624962,
      "grad_norm": 0.09207890927791595,
      "learning_rate": 4.0457605229774056e-05,
      "loss": 0.1175,
      "step": 17200
    },
    {
      "epoch": 0.5897794293116967,
      "grad_norm": 0.16757649183273315,
      "learning_rate": 4.040046171956251e-05,
      "loss": 0.1198,
      "step": 17300
    },
    {
      "epoch": 0.5931885589608973,
      "grad_norm": 0.123021699488163,
      "learning_rate": 4.034331820935097e-05,
      "loss": 0.1184,
      "step": 17400
    },
    {
      "epoch": 0.5965976886100979,
      "grad_norm": 0.17190927267074585,
      "learning_rate": 4.0286174699139425e-05,
      "loss": 0.1229,
      "step": 17500
    },
    {
      "epoch": 0.6000068182592984,
      "grad_norm": 0.14384806156158447,
      "learning_rate": 4.0229031188927875e-05,
      "loss": 0.1179,
      "step": 17600
    },
    {
      "epoch": 0.603415947908499,
      "grad_norm": 0.15186770260334015,
      "learning_rate": 4.017188767871633e-05,
      "loss": 0.1167,
      "step": 17700
    },
    {
      "epoch": 0.6068250775576995,
      "grad_norm": 0.10134027898311615,
      "learning_rate": 4.011474416850479e-05,
      "loss": 0.1163,
      "step": 17800
    },
    {
      "epoch": 0.6102342072069,
      "grad_norm": 0.10509201139211655,
      "learning_rate": 4.005760065829324e-05,
      "loss": 0.1221,
      "step": 17900
    },
    {
      "epoch": 0.6136433368561006,
      "grad_norm": 0.11573418974876404,
      "learning_rate": 4.0000457148081695e-05,
      "loss": 0.1206,
      "step": 18000
    },
    {
      "epoch": 0.6136433368561006,
      "eval_loss": 0.11511659622192383,
      "eval_runtime": 1602.2918,
      "eval_samples_per_second": 8.136,
      "eval_steps_per_second": 2.035,
      "step": 18000
    }
  ],
  "logging_steps": 100,
  "max_steps": 87999,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.0081195933696e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
